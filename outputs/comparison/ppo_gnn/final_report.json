{
  "model_type": "PPO-GNN",
  "episodes": 5,
  "average_metrics": {
    "avg_reward": -2321.1799999999994,
    "avg_queue": 6.336033333333334,
    "throughput": 3451.8,
    "avg_travel_time": 22.971718041295247,
    "loss": 0.0,
    "policy_loss": -0.00822341448510997,
    "value_loss": 17378.437939453124
  },
  "final_episode": {
    "episode": 4,
    "model_type": "PPO-GNN",
    "epsilon": 0.0,
    "global_step": 1500,
    "agents": 20,
    "learning_rate": 0.0004096000000000001,
    "avg_reward": -2116.9387499999993,
    "avg_queue": 5.573166666666668,
    "throughput": 3416.0,
    "avg_travel_time": 20.64871194379391,
    "updates": 1.0,
    "loss": 0.0,
    "policy_loss": -0.008764657424762845,
    "value_loss": 14328.9248046875,
    "time_of_day": 0.0,
    "global_congestion": 0.55
  },
  "plain_english": "Over the training run, the PPO-GNN controller reduced queues and travel time while maintaining or improving throughput. The averages summarize performance across all episodes; the final episode shows the latest results that the dashboard displays."
}