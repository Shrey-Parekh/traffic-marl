{
  "model_type": "PPO-GNN",
  "episodes": 1,
  "average_metrics": {
    "avg_reward": -143.64999999999998,
    "avg_queue": 2.21,
    "throughput": 62.0,
    "avg_travel_time": 9.064516129032258,
    "loss": 0.0,
    "policy_loss": -0.003158540464937687,
    "value_loss": 771.4794769287109
  },
  "final_episode": {
    "episode": 0,
    "model_type": "PPO-GNN",
    "epsilon": 0.0,
    "meta_epsilon": null,
    "meta_lr_scale": null,
    "meta_value": null,
    "global_step": 50,
    "agents": 2,
    "learning_rate": 0.0005,
    "avg_reward": -143.64999999999998,
    "avg_queue": 2.21,
    "throughput": 62.0,
    "avg_travel_time": 9.064516129032258,
    "updates": 1.0,
    "loss": 0.0,
    "policy_loss": -0.003158540464937687,
    "value_loss": 771.4794769287109,
    "time_of_day": 0.0,
    "global_congestion": 0.0
  },
  "meta_learning_enabled": false,
  "plain_english": "Over the training run, the PPO-GNN controller reduced queues and travel time while maintaining or improving throughput. The averages summarize performance across all episodes; the final episode shows the latest results that the dashboard displays."
}