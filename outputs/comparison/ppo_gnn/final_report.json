{
  "model_type": "PPO-GNN",
  "episodes": 20,
  "average_metrics": {
    "avg_reward": -1211.7956250000002,
    "avg_queue": 4.683281249999999,
    "throughput": 1844.7,
    "avg_travel_time": 17.624380253223226,
    "loss": 0.0,
    "policy_loss": 0.0025569596840796295,
    "value_loss": 9572.111096191406
  },
  "final_episode": {
    "episode": 19,
    "model_type": "PPO-GNN",
    "epsilon": 0.0,
    "global_step": 4000,
    "agents": 16,
    "learning_rate": 0.0005120000000000001,
    "avg_reward": -1244.3828125000002,
    "avg_queue": 4.8003125,
    "throughput": 1873.0,
    "avg_travel_time": 17.86545648691938,
    "updates": 1.0,
    "loss": 0.0,
    "policy_loss": -0.0030509839416481555,
    "value_loss": 7846.4808349609375,
    "time_of_day": 0.0,
    "global_congestion": 0.375
  },
  "plain_english": "Over the training run, the PPO-GNN controller reduced queues and travel time while maintaining or improving throughput. The averages summarize performance across all episodes; the final episode shows the latest results that the dashboard displays."
}