{
  "model_type": "GNN-DQN",
  "episodes": 50,
  "average_metrics": {
    "avg_reward": -1584.4466666666665,
    "avg_queue": 3.3057166666666666,
    "throughput": 2119.92,
    "avg_travel_time": 14.994034796594958,
    "loss": 2.708712792006652,
    "policy_loss": 0.0,
    "value_loss": 0.0
  },
  "final_episode": {
    "episode": 49,
    "model_type": "GNN-DQN",
    "epsilon": 0.01,
    "global_step": 15000,
    "agents": 12,
    "learning_rate": 4.0960000000000014e-05,
    "avg_reward": -1618.2500000000005,
    "avg_queue": 3.4274999999999984,
    "throughput": 2096.0,
    "avg_travel_time": 15.49618320610687,
    "updates": 300.0,
    "loss": 2.5332498693466188,
    "policy_loss": 0.0,
    "value_loss": 0.0,
    "time_of_day": 0.0,
    "global_congestion": 0.5833333333333334
  },
  "plain_english": "Over the training run, the GNN-DQN controller reduced queues and travel time while maintaining or improving throughput. The averages summarize performance across all episodes; the final episode shows the latest results that the dashboard displays."
}