{
  "model_type": "GNN-DQN",
  "episodes": 30,
  "average_metrics": {
    "avg_reward": -1656.8444444444442,
    "avg_queue": 3.7906388888888882,
    "throughput": 2128.233333333333,
    "avg_travel_time": 14.605964825481362,
    "loss": 3.0315981122588593,
    "policy_loss": 0.0,
    "value_loss": 0.0
  },
  "final_episode": {
    "episode": 29,
    "model_type": "GNN-DQN",
    "epsilon": 0.01,
    "global_step": 9000,
    "agents": 12,
    "learning_rate": 4.0960000000000014e-05,
    "avg_reward": -1842.0833333333337,
    "avg_queue": 4.247499999999998,
    "throughput": 2135.0,
    "avg_travel_time": 15.981264637002342,
    "updates": 300.0,
    "loss": 3.2476039111614226,
    "policy_loss": 0.0,
    "value_loss": 0.0,
    "time_of_day": 0.0,
    "global_congestion": 0.5
  },
  "plain_english": "Over the training run, the GNN-DQN controller reduced queues and travel time while maintaining or improving throughput. The averages summarize performance across all episodes; the final episode shows the latest results that the dashboard displays."
}