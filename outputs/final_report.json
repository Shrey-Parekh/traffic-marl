{
  "model_type": "GNN-DQN",
  "episodes": 25,
  "average_metrics": {
    "avg_reward": 192.95759999999987,
    "avg_queue": 3.4444800000000004,
    "throughput": 1754.16,
    "avg_travel_time": 13.56964194280331,
    "loss": 0.5642532241065704,
    "policy_loss": 0.0,
    "value_loss": 0.0
  },
  "final_episode": {
    "episode": 24,
    "model_type": "GNN-DQN",
    "epsilon": 0.26182,
    "global_step": 7500,
    "training_updates": 300.0,
    "agents": 10,
    "learning_rate": 0.0001,
    "avg_reward": 186.88999999999987,
    "avg_queue": 3.241666666666669,
    "throughput": 1699.0,
    "avg_travel_time": 13.27839905826957,
    "updates": 300.0,
    "loss": 0.6134427163998286,
    "policy_loss": 0.0,
    "value_loss": 0.0,
    "time_of_day": 0.0,
    "global_congestion": 0.2
  },
  "plain_english": "Over the training run, the GNN-DQN controller reduced queues and travel time while maintaining or improving throughput. The averages summarize performance across all episodes; the final episode shows the latest results that the dashboard displays."
}